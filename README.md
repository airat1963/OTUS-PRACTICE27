# Проект автоматического регулярного переобучения модели обнаружения мошенничества

Данный проект представляет собой MLOps-инфраструктуру для автоматического регулярного переобучения модели обнаружения мошенничества в финансовых транзакциях. Инфраструктура создается и управляется с помощью Terraform в облаке Yandex Cloud.

## Компоненты проекта

Проект состоит из следующих компонентов:

1. **Инфраструктура** (директория `/infra`):
   - Кластер Airflow - оркестрация процессов
   - Сервер MLflow - отслеживание экспериментов и хранение моделей
   - Кластер PostgreSQL - хранение метаданных экспериментов MLflow
   - S3-хранилище - хранение артефактов экспериментов и исходных данных
   - Сеть, подсеть и другие ресурсы Yandex Cloud

2. **Модель** (директория `/src`):
   - PySpark-скрипт для обучения модели с логикой сравнения и регистрации моделей в MLflow

3. **Оркестрация** (директория `/dags`):
   - Airflow DAG для регулярного запуска процесса обучения на времяном кластере Dataproc

1. **Вспомогательные скрипты** (директория `/scripts`):
   - Генерация демонстрационных данных для обучения
   - Создание архива виртуального окружения

## Архитектура решения

1. **Исходные данные** хранятся в S3-хранилище
2. **Airflow DAG** запускается по расписанию и создает кластер Dataproc
3. **PySpark скрипт** запускается на кластере Dataproc, обучает модель и логирует ее в MLflow
4. **MLflow** отслеживает эксперименты, хранит модели и метрики
5. **PostgreSQL** хранит метаданные экспериментов MLflow

## Начало работы

### Предварительные требования

- [Terraform](https://www.terraform.io/downloads.html) >= 1.0.0
- [Yandex Cloud CLI](https://cloud.yandex.ru/docs/cli/quickstart)
- [Python](https://www.python.org/downloads/) == 3.11
- [s3cmd](https://s3tools.org/download)

### Шаг 1: Создание инфраструктуры с помощью Terraform

```bash
cd infra
terraform init
terraform apply

# make
make init
make apply
```

После создания инфраструктуры, Terraform выведет значения выходных переменных, включая URL сервера MLflow и другие необходимые параметры.

### Шаг 2: Генерация демонстрационных данных

```bash
make create-data
```

Скрипт создаст синтетические данные о транзакциях в директории `data/input_data`.

### Шаг 3: Подготовка и загрузка ресурсов в S3-хранилище

Вы можете использовать команды Makefile для загрузки необходимых ресурсов:

```bash
# Создать и загрузить виртуальное окружение
make create-venv-archive
make upload-venv-to-bucket

# Загрузить исходный код модели
make upload-src-to-bucket

# Загрузить DAG файлы
make upload-dags-to-bucket

# Загрузить данные в S3
make upload-data-to-bucket

# Или выполнить полное развертывание одной командой
make deploy-full
```

### Шаг 4: Настройка Airflow

1. Загрузите переменные окружения в UI Airflow из файла variables.json.

2. Включите DAG в веб-интерфейсе Airflow.

### Шаг 5: Мониторинг и получение результатов

Вы можете проверить список экземпляров виртуальных машин:
```bash
make instance-list
```

Для мониторинга кластера Airflow используйте:
```bash
make airflow-cluster-mon
```

Чтобы загрузить результаты обработки из S3-хранилища:
```bash
make download-output-data-from-bucket
```

## Работа с MLflow

После запуска MLflow-сервера вы можете открыть его веб-интерфейс по адресу, который был выведен после выполнения `terraform apply`.

В интерфейсе MLflow вы сможете:
- Просматривать эксперименты и их метрики
- Сравнивать модели между собой
- Загружать зарегистрированные модели

## Структура проекта

```
/
├── dags/                  # Airflow DAGs
│   └── fraud_detection_training.py
├── data/                  # Данные для обучения и результаты
│   ├── input_data/        # Входные данные
│   └── output_data/       # Результаты работы модели
├── infra/                 # Terraform конфигурация
│   ├── main.tf
│   ├── variables.tf 
│   ├── outputs.tf
│   └── terraform.tfvars.example
├── scripts/               # Вспомогательные скрипты
│   ├── create_demo_data.py
│   ├── create_venv_archive.sh
│   └── upload_to_s3.sh
├── src/                   # Исходный код модели
│   └── fraud_detection_model.py
├── utils/                 # Утилиты
│   └── push_secrets_to_github_repo.py
├── venvs/                 # Архивы виртуальных окружений
├── .env                   # Файл с переменными окружения
├── Makefile               # Makefile для автоматизации задач
└── README.md              # Это файл
```

## Синхронизация с удаленным окружением

Для работы с удаленным окружением используйте:

```bash
# Синхронизация локального кода с удаленным
make sync-repo

# Получение актуального .env файла с удаленного сервера
make sync-env
```

## Автоматическое переобучение модели

После настройки всех компонентов система будет автоматически:

1. Запускать процесс обучения по расписанию (по умолчанию каждые 60 минут)
2. Сравнивать метрики новой модели с текущей зарегистрированной моделью
3. Регистрировать новую модель в MLflow, если она показывает лучшие результаты

## Разработка и вклад в проект

Если вы хотите внести свой вклад в проект:

1. Форкните репозиторий
2. Создайте ветку для вашей функциональности
3. Сделайте коммиты ваших изменений
4. Отправьте пулл-реквест в основной репозиторий

## Лицензия

Этот проект распространяется под лицензией MIT.

## Автор

[NickOsipov](https://t.me.com/NickOsipov)
